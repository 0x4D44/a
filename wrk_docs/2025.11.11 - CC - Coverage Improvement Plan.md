# Coverage Improvement Plan
**Project:** Alias Manager (`a`)
**Current Coverage:** 84.91%
**Target Coverage:** 98.00%
**Gap:** 13.09% (337 uncovered lines)

---

## Overview

This document outlines a systematic, multistage approach to improve code coverage from 84.91% to 98% through targeted test additions.

---

## Phase 1: Main Function & CLI Argument Coverage (Target: 90%)

**Goal:** Achieve 90% coverage by testing all main function branches
**Estimated Impact:** +5% coverage (~111 lines)
**Duration:** 2-3 hours

### Tasks

#### 1.1 Enhanced CLI Integration Tests
**File:** `tests/cli_smoke.rs`

**Tests to Add:**
- [ ] `test_add_alias_success` - Add alias via CLI
- [ ] `test_add_alias_missing_arguments` - Error when missing required args
- [ ] `test_add_alias_invalid_name` - Reserved name rejection
- [ ] `test_remove_alias_success` - Remove alias via CLI
- [ ] `test_remove_alias_not_found` - Error when alias doesn't exist
- [ ] `test_list_with_various_filters` - Different filter patterns
- [ ] `test_import_config_success` - Import from file path
- [ ] `test_import_config_missing_file` - Error for missing import file
- [ ] `test_execute_alias_with_args` - Execute alias with arguments
- [ ] `test_execute_alias_not_found` - Error for undefined alias
- [ ] `test_chained_commands_via_cli` - Execute command chains
- [ ] `test_add_with_description` - Add alias with --desc flag
- [ ] `test_add_chain_commands` - Add chain with --and/--or/--always
- [ ] `test_parallel_execution_flag` - Execute with --parallel

**Coverage Target:** Main function lines 1810-2244

#### 1.2 Error Path Tests for Config Operations
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_save_config_disk_full` - Handle disk full error (mock)
- [ ] `test_save_config_permission_denied` - Handle permission errors
- [ ] `test_load_config_corrupted_json` - Malformed JSON handling
- [ ] `test_config_path_invalid_home` - Handle invalid $HOME
- [ ] `test_config_directory_creation_failure` - mkdir failure handling

**Coverage Target:** Config I/O error paths

---

## Phase 2: Error Handling & GitHub Integration (Target: 95%)

**Goal:** Achieve 95% coverage with comprehensive error path testing
**Estimated Impact:** +5% coverage (~111 lines)
**Duration:** 3-4 hours

### Tasks

#### 2.1 GitHub API Error Scenarios
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_push_unauthorized_401` - Invalid/expired token
- [ ] `test_push_forbidden_403` - Insufficient permissions
- [ ] `test_push_not_found_404` - Repository doesn't exist
- [ ] `test_push_rate_limit_429` - GitHub rate limiting
- [ ] `test_push_server_error_500` - GitHub internal error
- [ ] `test_push_service_unavailable_503` - GitHub downtime
- [ ] `test_pull_malformed_json_response` - Invalid JSON from GitHub
- [ ] `test_pull_invalid_base64_content` - Corrupted content encoding
- [ ] `test_pull_empty_response_body` - Empty file from GitHub
- [ ] `test_github_token_precedence_all_sources` - Test all 3 token sources
- [ ] `test_github_token_from_gh_status_malformed` - Invalid gh CLI output
- [ ] `test_github_token_from_git_credentials_not_found` - Missing credentials

**Coverage Target:** GitHub sync error paths (lines 648-802)

#### 2.2 Command Execution Edge Cases
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_execute_exit_code_variations` - Test codes 0,1,2,127,255
- [ ] `test_execute_command_not_found` - Missing executable
- [ ] `test_execute_with_signal_termination` - Simulated signal kills
- [ ] `test_execute_empty_command_string` - Empty command handling
- [ ] `test_execute_only_whitespace` - Whitespace-only commands
- [ ] `test_execute_with_special_chars` - Special characters in args
- [ ] `test_execute_very_long_command_line` - Argument length limits
- [ ] `test_execute_with_null_bytes` - Invalid character handling

**Coverage Target:** Command execution edge cases (lines 1404-1450)

#### 2.3 Interactive Input Scenarios
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_confirm_overwrite_empty_input` - Just pressing enter
- [ ] `test_confirm_overwrite_whitespace_variations` - " y ", "\ty\n"
- [ ] `test_confirm_overwrite_invalid_responses` - "maybe", "yes please"
- [ ] `test_confirm_overwrite_eof_handling` - Ctrl+D simulation
- [ ] `test_confirm_overwrite_multiple_attempts` - Invalid then valid input

**Coverage Target:** Interactive input paths (lines 870-896)

---

## Phase 3: Edge Cases & Advanced Scenarios (Target: 98%)

**Goal:** Achieve 98% coverage with comprehensive edge case testing
**Estimated Impact:** +3% coverage (~67 lines)
**Duration:** 2-3 hours

### Tasks

#### 3.1 Parallel Execution Comprehensive Testing
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_parallel_all_succeed` - All commands exit 0
- [ ] `test_parallel_all_fail` - All commands exit non-zero
- [ ] `test_parallel_mixed_results` - Some succeed, some fail
- [ ] `test_parallel_with_different_exit_codes` - Codes 0,1,2,127
- [ ] `test_parallel_thread_panic_handling` - Graceful panic recovery
- [ ] `test_parallel_with_very_long_commands` - Performance under load
- [ ] `test_parallel_with_arguments` - Arg passing to parallel commands

**Coverage Target:** Parallel execution (lines 1283-1393)

#### 3.2 Parameter Substitution Edge Cases
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_substitute_with_unicode` - Non-ASCII characters
- [ ] `test_substitute_with_emoji` - Emoji in parameters
- [ ] `test_substitute_mixed_escaped_unescaped` - `$$1 $2 $$3 $4`
- [ ] `test_substitute_at_boundaries` - `$1`, `$1middle`, `end$1`
- [ ] `test_substitute_with_newlines` - Multi-line commands
- [ ] `test_substitute_very_large_arg_count` - 100+ arguments

**Coverage Target:** Parameter substitution edge cases (lines 1451-1509)

#### 3.3 Sequential Chain Advanced Scenarios
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_sequential_with_if_code_variations` - Test multiple --if-code values
- [ ] `test_sequential_long_chain` - 10+ command chain
- [ ] `test_sequential_all_operators_mixed` - &&, ||, ;, --if-code in one chain
- [ ] `test_sequential_skip_messaging` - Verify skip messages printed
- [ ] `test_sequential_with_arguments_mid_chain` - Args passed correctly

**Coverage Target:** Sequential execution edge cases (lines 1193-1282)

#### 3.4 Config File Edge Cases
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_load_empty_config_file` - Zero-byte file
- [ ] `test_load_large_config` - 1000+ aliases
- [ ] `test_load_unicode_alias_names` - Non-ASCII names
- [ ] `test_load_with_bom` - UTF-8 BOM handling
- [ ] `test_migrate_empty_legacy_config` - Empty old format
- [ ] `test_export_with_unicode_paths` - Non-ASCII directory names
- [ ] `test_export_overwrite_existing` - Confirm overwrite behavior

**Coverage Target:** Config file edge cases (lines 452-508)

#### 3.5 Display & Formatting Functions
**File:** `src/main.rs` (unit tests section)

**Tests to Add:**
- [ ] `test_list_with_very_long_commands` - Truncation behavior
- [ ] `test_which_with_complex_chain_display` - Format verification
- [ ] `test_help_output_formatting` - Verify ANSI codes
- [ ] `test_version_banner_format` - Check version display
- [ ] `test_config_location_display` - Path display test

**Coverage Target:** Display functions (lines 902-1113)

#### 3.6 Windows-Specific Code (Conditional)
**File:** `src/main.rs` (unit tests section)

**Note:** These tests may need conditional compilation or mocking

**Tests to Add (if feasible):**
- [ ] `test_windows_program_resolution_with_pathext` - Mock Windows env
- [ ] `test_windows_program_with_extension` - .exe, .bat, .cmd
- [ ] `test_windows_program_in_path` - PATH lookup simulation
- [ ] `test_windows_program_with_separator` - Backslash paths
- [ ] `test_windows_empty_pathext` - Default extension handling

**Coverage Target:** Windows-specific code (lines 98-177)

---

## Implementation Strategy

### Test Development Approach

1. **Isolation First:** Write tests for independent functions before dependent ones
2. **Mock Everything:** Leverage existing mock infrastructure (CommandRunner, GitHubClient)
3. **Error Injection:** Use Result types to simulate failures systematically
4. **Incremental Validation:** Run coverage after each test batch to track progress

### Code Organization

```
tests/
├── cli_smoke.rs           # Integration tests (expand existing)
src/
└── main.rs
    └── #[cfg(test)]
        └── mod tests
            ├── config_tests       (existing, expand)
            ├── execution_tests    (existing, expand)
            ├── github_tests       (existing, expand)
            ├── parameter_tests    (existing, expand)
            ├── cli_arg_tests      (NEW - Phase 1)
            ├── error_path_tests   (NEW - Phase 2)
            └── edge_case_tests    (NEW - Phase 3)
```

### Validation Checkpoints

After each phase:
1. Run `cargo llvm-cov --all-features --workspace`
2. Verify coverage percentage meets phase target
3. Check that no existing tests were broken
4. Review HTML coverage report for remaining gaps
5. Document any unreachable code or deliberate exclusions

---

## Success Criteria

### Phase 1 Complete (90%)
- [ ] All main function branches have tests
- [ ] Basic error paths covered
- [ ] CLI integration tests comprehensive
- [ ] Coverage report shows 90.00% ± 0.5%

### Phase 2 Complete (95%)
- [ ] All GitHub API error codes tested
- [ ] Command execution errors covered
- [ ] Interactive input edge cases tested
- [ ] Coverage report shows 95.00% ± 0.5%

### Phase 3 Complete (98%)
- [ ] Parallel execution fully tested
- [ ] All parameter substitution edge cases covered
- [ ] Config file edge cases tested
- [ ] Display functions covered
- [ ] Coverage report shows 98.00% ± 0.5%

---

## Risk Mitigation

### Potential Blockers

1. **Windows-specific code:** May be impossible to fully test on Linux CI
   - **Mitigation:** Document as acceptable gap OR add conditional compilation for mocks

2. **True non-determinism:** Race conditions in parallel execution
   - **Mitigation:** Use deterministic test fixtures and timeouts

3. **External dependencies:** GitHub API, filesystem
   - **Mitigation:** Comprehensive mocking (already in place)

4. **Unreachable code:** Dead code that should be removed
   - **Mitigation:** Identify with `#[cfg(coverage)]` exclusions and document

### Quality Assurance

- All new tests must pass on first run
- No flaky tests tolerated (fix or remove)
- Test execution time should remain under 1 second total
- Each test should verify one specific behavior

---

## Tracking & Reporting

### After Each Phase

Generate updated reports:
```bash
cargo llvm-cov --all-features --workspace > coverage_report_phase_N.txt
cargo llvm-cov --all-features --workspace --html
cp target/llvm-cov/html/index.html wrk_docs/coverage_phase_N.html
```

Update this document with:
- [ ] Actual coverage achieved
- [ ] Number of tests added
- [ ] Time spent
- [ ] Blockers encountered
- [ ] Remaining gaps identified

---

## Timeline

| Phase | Target | Duration | Start | End |
|-------|--------|----------|-------|-----|
| Phase 1 | 90% | 2-3 hrs | TBD | TBD |
| Phase 2 | 95% | 3-4 hrs | TBD | TBD |
| Phase 3 | 98% | 2-3 hrs | TBD | TBD |
| **Total** | **98%** | **7-10 hrs** | **TBD** | **TBD** |

---

## Conclusion

This plan provides a systematic approach to achieving 98% code coverage through:
- Incremental phases with clear milestones
- Comprehensive error path testing
- Edge case identification and coverage
- Existing mock infrastructure leverage
- Quality-focused test development

**Next Step:** Begin Phase 1 implementation with CLI argument tests.

---

**Document Version:** 1.0
**Last Updated:** 2025-11-11
**Plan Status:** Ready for Implementation
